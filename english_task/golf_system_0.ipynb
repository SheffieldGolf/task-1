{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (English) System \\#1\n",
    "\n",
    "The baseline provided by CLEF achieves the following average precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Baseline AVGP: 0.4378835232034028\n",
      "Ngram Baseline AVGP: 0.8178620442105289\n"
     ]
    }
   ],
   "source": [
    "%run baselines/baselines.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "\n",
    "Read in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_worthiness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234964653014384644</th>\n",
       "      <td>Since this will never get reported by the medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234869939720216578</th>\n",
       "      <td>Thanks, #MichaelBloomberg. Here’s a handy litt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234873136304267267</th>\n",
       "      <td>Folks, when you say \"The corona virus isn't a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235071285027147776</th>\n",
       "      <td>Just 1 case of Corona Virus in India and  peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234911110861594624</th>\n",
       "      <td>President  @realDonaldTrump  made a commitment...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tweet_text  claim  \\\n",
       "tweet_id                                                                        \n",
       "1234964653014384644  Since this will never get reported by the medi...      1   \n",
       "1234869939720216578  Thanks, #MichaelBloomberg. Here’s a handy litt...      0   \n",
       "1234873136304267267  Folks, when you say \"The corona virus isn't a ...      0   \n",
       "1235071285027147776  Just 1 case of Corona Virus in India and  peop...      1   \n",
       "1234911110861594624  President  @realDonaldTrump  made a commitment...      1   \n",
       "\n",
       "                     claim_worthiness  \n",
       "tweet_id                               \n",
       "1234964653014384644                 1  \n",
       "1234869939720216578                 0  \n",
       "1234873136304267267                 0  \n",
       "1235071285027147776                 1  \n",
       "1234911110861594624                 1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "np.random.seed(42)\n",
    "\n",
    "train = pd.read_csv('data/training.tsv', sep='\\t', header=0, index_col='tweet_id').drop(['tweet_url', 'topic_id'], axis=1)\n",
    "dev = pd.read_csv('data/dev.tsv', sep='\\t', header=0, index_col='tweet_id').drop(['tweet_url', 'topic_id'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functionality from Arabic task to preprocess the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tommcdonald/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# before using nltk.corpus.stopwords, following the cell above to download stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "url_pattern = r\"https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}\"\n",
    "token_pattern = r\"\\b[A-Za-z][A-Za-z]+\\b\"\n",
    "\n",
    "# function of preprocessing text, tokenization, stopwords removal, stemming\n",
    "def preprocess_text(text, url_pattern = url_pattern, token_pattern=token_pattern, \n",
    "                    with_urlrm=True, with_stopwordsrm=True, stopwords=stopwords, with_stemming=False):\n",
    "    # url removal \n",
    "    if with_urlrm == True:\n",
    "        text = re.sub(url_pattern, \"\", text)\n",
    "        \n",
    "    # lower case \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, text_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    text_processed = \" \".join(words)\n",
    "    \n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_stemming = []\n",
    "dev_with_stemming = []\n",
    "\n",
    "for i, text in enumerate(train[\"tweet_text\"]):\n",
    "    train_with_stemming.append(preprocess_text(text, with_stemming=True))\n",
    "    if i < len(dev):\n",
    "        dev_with_stemming.append(preprocess_text(dev[\"tweet_text\"].iloc[i], with_stemming=True))\n",
    "    \n",
    "train[\"processed_text\"] = train_with_stemming\n",
    "dev[\"processed_text\"] = dev_with_stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TFIDF Features\n",
    "\n",
    "Create TFIDF vectors from processed text, using unigrams, bigrams and trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aag</th>\n",
       "      <th>aag badh</th>\n",
       "      <th>aag badh raha</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaron ramsey</th>\n",
       "      <th>aaron ramsey score</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab cbn</th>\n",
       "      <th>ab cbn news</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>zero children</th>\n",
       "      <th>zero children year</th>\n",
       "      <th>zero school</th>\n",
       "      <th>zero school close</th>\n",
       "      <th>zhangyix</th>\n",
       "      <th>zika</th>\n",
       "      <th>zika corona</th>\n",
       "      <th>zika corona elect</th>\n",
       "      <th>zika ebola</th>\n",
       "      <th>zika ebola lyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aag  aag badh  aag badh raha  aaron  aaron ramsey  aaron ramsey score   ab  \\\n",
       "0  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "1  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "2  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "3  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "4  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "\n",
       "   ab cbn  ab cbn news  abandon  ...  zero children  zero children year  \\\n",
       "0     0.0          0.0      0.0  ...            0.0                 0.0   \n",
       "1     0.0          0.0      0.0  ...            0.0                 0.0   \n",
       "2     0.0          0.0      0.0  ...            0.0                 0.0   \n",
       "3     0.0          0.0      0.0  ...            0.0                 0.0   \n",
       "4     0.0          0.0      0.0  ...            0.0                 0.0   \n",
       "\n",
       "   zero school  zero school close  zhangyix  zika  zika corona  \\\n",
       "0          0.0                0.0       0.0   0.0          0.0   \n",
       "1          0.0                0.0       0.0   0.0          0.0   \n",
       "2          0.0                0.0       0.0   0.0          0.0   \n",
       "3          0.0                0.0       0.0   0.0          0.0   \n",
       "4          0.0                0.0       0.0   0.0          0.0   \n",
       "\n",
       "   zika corona elect  zika ebola  zika ebola lyme  \n",
       "0                0.0         0.0              0.0  \n",
       "1                0.0         0.0              0.0  \n",
       "2                0.0         0.0              0.0  \n",
       "3                0.0         0.0              0.0  \n",
       "4                0.0         0.0              0.0  \n",
       "\n",
       "[5 rows x 16978 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "X_tr = vectorizer.fit_transform(train_with_stemming)\n",
    "X_dev = vectorizer.transform(dev_with_stemming)\n",
    "\n",
    "X_tr_df = pd.DataFrame.sparse.from_spmatrix(X_tr, \n",
    "                                            columns=vectorizer.get_feature_names())\n",
    "X_dev_df = pd.DataFrame.sparse.from_spmatrix(X_dev, \n",
    "                                             columns=vectorizer.get_feature_names())\n",
    "\n",
    "X_tr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelling\n",
    "\n",
    "Get tweet labels and use them with the training data to fit some models. 'claim' is 1 if the tweet is a claim and 0 otherwise, whilst 'worthy' is 1 if the tweet is worth fact checking and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_claim = train.claim.to_numpy().reshape(-1, 1)\n",
    "y_tr_worthy = train.claim_worthiness.to_numpy().reshape(-1, 1)\n",
    "y_dev_claim = train.claim.to_numpy().reshape(-1, 1)\n",
    "y_dev_worthy = train.claim_worthiness.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Test MAP Score: 0.537 \n",
      "\n",
      "Random Forest\n",
      "Test MAP Score: 0.77 \n",
      "\n",
      "SGD\n",
      "Test MAP Score: 0.755 \n",
      "\n",
      "AdaBoost\n",
      "Test MAP Score: 0.626 \n",
      "\n",
      "Gradient Boosting\n",
      "Test MAP Score: 0.724 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [GaussianNB(), RandomForestClassifier(n_estimators=100), SGDClassifier(), \n",
    "          AdaBoostClassifier(), GradientBoostingClassifier()]\n",
    "models_str = [\"Naive Bayes\", \"Random Forest\", \"SGD\", \"AdaBoost\", \"Gradient Boosting\"]\n",
    "best_models = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    scoring = {'map':'average_precision'}\n",
    "    scores = cross_validate(model, X_tr_df, y_tr_worthy, scoring=scoring, cv=5, \n",
    "                            return_train_score=True, return_estimator=True)\n",
    "    best_models.append(scores[\"estimator\"][np.argmax(scores[\"test_map\"])])\n",
    "    print(models_str[i])\n",
    "    print(\"Test MAP Score:\", round(np.mean(scores['test_map']), 3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on full training set using best model (Random Forest) and predict probabilities of check-worthiness for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_tr_df, y_tr_worthy)\n",
    "preds_proba = rf.predict_proba(X_dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create correct format for data as specified in README.md and use 'scorer' to compare the system to the gold standard data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['topic_id', 'tweet_id', 'score', 'run_id'])\n",
    "results['tweet_id'] = list(dev.index)\n",
    "results['score'] = [x[1] for x in preds_proba]\n",
    "results['topic_id'] = 'covid-19'\n",
    "results['run_id'] = 'Model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235714275752267776</td>\n",
       "      <td>0.575</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235256530728972290</td>\n",
       "      <td>0.180</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235648554338791427</td>\n",
       "      <td>0.270</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235674258858061825</td>\n",
       "      <td>0.425</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235663306246860800</td>\n",
       "      <td>0.330</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235914080931766274</td>\n",
       "      <td>0.150</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235770706765451264</td>\n",
       "      <td>0.200</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235973416995315712</td>\n",
       "      <td>0.475</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235675024738185239</td>\n",
       "      <td>0.165</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235682242774437888</td>\n",
       "      <td>0.365</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic_id             tweet_id  score   run_id\n",
       "0    covid-19  1235714275752267776  0.575  Model_1\n",
       "1    covid-19  1235256530728972290  0.180  Model_1\n",
       "2    covid-19  1235648554338791427  0.270  Model_1\n",
       "3    covid-19  1235674258858061825  0.425  Model_1\n",
       "4    covid-19  1235663306246860800  0.330  Model_1\n",
       "..        ...                  ...    ...      ...\n",
       "145  covid-19  1235914080931766274  0.150  Model_1\n",
       "146  covid-19  1235770706765451264  0.200  Model_1\n",
       "147  covid-19  1235973416995315712  0.475  Model_1\n",
       "148  covid-19  1235675024738185239  0.165  Model_1\n",
       "149  covid-19  1235682242774437888  0.365  Model_1\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('golf_system_results.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python3 scorer/main.py --gold_file_path=\"./data/dev.tsv\" --pred_file_path=\"./golf_system_results.tsv\"\n",
    "INFO : Started evaluating results for Task 5 ...\n",
    "INFO : Reading gold predictions from file ./data/dev.tsv\n",
    "INFO : Reading predicted ranking order from file ./golf_system_results.tsv\n",
    "INFO : ========================================= RESULTS for golf_system_results.tsv ==========================================\n",
    "INFO : AVERAGE PRECISION:            0.8104    \n",
    "INFO : ========================================================================================================================\n",
    "INFO : RECIPROCAL RANK:              1.0000    \n",
    "INFO : ========================================================================================================================\n",
    "INFO : R-PRECISION (R=72):           0.7500    \n",
    "INFO : ========================================================================================================================\n",
    "INFO : PRECISION@N:                  @1        @3        @5        @10       @20       @50       \n",
    "INFO :                               1.0000    1.0000    1.0000    0.9000    0.9000    0.7600    \n",
    "INFO : ========================================================================================================================\n",
    "INFO : Description of the evaluation metrics: \n",
    "INFO : !!! THE OFFICIAL METRIC USED FOR THE COMPETITION RANKING IS MEAN AVERAGE PRECISION (MAP) !!!\n",
    "INFO : R-Precision is Precision at R, where R is the number of relevant line_numbers for the evaluated set.\n",
    "INFO : Average Precision is the precision@N, estimated only @ each relevant line_number and then averaged over the number of relevant line_numbers.\n",
    "INFO : Reciprocal Rank is the reciprocal of the rank of the first relevant line_number in the list of predictions sorted by score (descendingly).\n",
    "INFO : Precision@N is precision estimated for the first N line_numbers in the provided ranked list.\n",
    "INFO : The MEAN versions of each metric are provided to average over multiple debates (each with separate prediction file).\n",
    "INFO : ========================================================================================================================\n",
    "INFO : ========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average precision of 0.8104 is just slightly below CLEF's 0.817 n-gram model baseline, and is considerably better than the random basline of ~ 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
