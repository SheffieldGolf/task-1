{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final System 1 - Random Forest w/ TFIDF on V2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "\n",
    "Read in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822 training instances\n",
      "140 test instances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>check_worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since this will never get reported by the medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks, #MichaelBloomberg. Here’s a handy litt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Folks, when you say \"The corona virus isn't a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just 1 case of Corona Virus in India and  peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>President  @realDonaldTrump  made a commitment...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  claim  check_worthiness\n",
       "0  Since this will never get reported by the medi...      1                 1\n",
       "1  Thanks, #MichaelBloomberg. Here’s a handy litt...      0                 0\n",
       "2  Folks, when you say \"The corona virus isn't a ...      0                 0\n",
       "3  Just 1 case of Corona Virus in India and  peop...      1                 0\n",
       "4  President  @realDonaldTrump  made a commitment...      1                 1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "np.random.seed(42)\n",
    "\n",
    "train = pd.read_csv('final_data/training_v2.tsv', sep='\\t', header=0, index_col='tweet_id').drop(['tweet_url', 'topic_id'], axis=1)\n",
    "dev = pd.read_csv('final_data/dev_v2.tsv', sep='\\t', header=0, index_col='tweet_id').drop(['tweet_url', 'topic_id'], axis=1)\n",
    "test = pd.read_csv('final_data/test-input.tsv', sep='\\t', header=0, index_col='tweet_id').drop(['tweet_url', 'topic_id'], axis=1)\n",
    "train = train.append(dev, ignore_index=True)\n",
    "print(len(train), 'training instances')\n",
    "print(len(test), 'test instances')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functionality from Arabic task to preprocess the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tommcdonald/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# before using nltk.corpus.stopwords, following the cell above to download stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "url_pattern = r\"https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}\"\n",
    "token_pattern = r\"\\b[A-Za-z][A-Za-z]+\\b\"\n",
    "\n",
    "# function of preprocessing text, tokenization, stopwords removal, stemming\n",
    "def preprocess_text(text, url_pattern = url_pattern, token_pattern=token_pattern, \n",
    "                    with_urlrm=True, with_stopwordsrm=True, stopwords=stopwords, with_stemming=False):\n",
    "    # url removal \n",
    "    if with_urlrm == True:\n",
    "        text = re.sub(url_pattern, \"\", text)\n",
    "        \n",
    "    # lower case \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, text_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    text_processed = \" \".join(words)\n",
    "    \n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_stemming = []\n",
    "test_with_stemming = []\n",
    "\n",
    "for i, text in enumerate(train[\"tweet_text\"]):\n",
    "    train_with_stemming.append(preprocess_text(text, with_stemming=True))\n",
    "    if i < len(test):\n",
    "        test_with_stemming.append(preprocess_text(test[\"tweet_text\"].iloc[i], with_stemming=True))\n",
    "    \n",
    "train[\"processed_text\"] = train_with_stemming\n",
    "test[\"processed_text\"] = test_with_stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TFIDF Features\n",
    "\n",
    "Create TFIDF vectors from processed text, using unigrams, bigrams and trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aag</th>\n",
       "      <th>aag badh</th>\n",
       "      <th>aag badh raha</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaron ramsey</th>\n",
       "      <th>aaron ramsey score</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab cbn</th>\n",
       "      <th>ab cbn news</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>zero self</th>\n",
       "      <th>zero self awar</th>\n",
       "      <th>zhangyix</th>\n",
       "      <th>zika</th>\n",
       "      <th>zika corona</th>\n",
       "      <th>zika corona elect</th>\n",
       "      <th>zika ebola</th>\n",
       "      <th>zika ebola lyme</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zombi apocalyps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27645 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aag  aag badh  aag badh raha  aaron  aaron ramsey  aaron ramsey score   ab  \\\n",
       "0  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "1  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "2  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "3  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "4  0.0       0.0            0.0    0.0           0.0                 0.0  0.0   \n",
       "\n",
       "   ab cbn  ab cbn news  abandon  ...  zero self  zero self awar  zhangyix  \\\n",
       "0     0.0          0.0      0.0  ...        0.0             0.0       0.0   \n",
       "1     0.0          0.0      0.0  ...        0.0             0.0       0.0   \n",
       "2     0.0          0.0      0.0  ...        0.0             0.0       0.0   \n",
       "3     0.0          0.0      0.0  ...        0.0             0.0       0.0   \n",
       "4     0.0          0.0      0.0  ...        0.0             0.0       0.0   \n",
       "\n",
       "   zika  zika corona  zika corona elect  zika ebola  zika ebola lyme  zombi  \\\n",
       "0   0.0          0.0                0.0         0.0              0.0    0.0   \n",
       "1   0.0          0.0                0.0         0.0              0.0    0.0   \n",
       "2   0.0          0.0                0.0         0.0              0.0    0.0   \n",
       "3   0.0          0.0                0.0         0.0              0.0    0.0   \n",
       "4   0.0          0.0                0.0         0.0              0.0    0.0   \n",
       "\n",
       "   zombi apocalyps  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 27645 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "X_tr = vectorizer.fit_transform(train_with_stemming)\n",
    "X_test = vectorizer.transform(test_with_stemming)\n",
    "\n",
    "X_tr_df = pd.DataFrame.sparse.from_spmatrix(X_tr, \n",
    "                                            columns=vectorizer.get_feature_names())\n",
    "X_test_df = pd.DataFrame.sparse.from_spmatrix(X_test, \n",
    "                                             columns=vectorizer.get_feature_names())\n",
    "\n",
    "X_tr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelling\n",
    "\n",
    "Get tweet labels and use them with the training data to fit some models. 'claim' is 1 if the tweet is a claim and 0 otherwise, whilst 'worthy' is 1 if the tweet is worth fact checking and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_claim = train.claim.to_numpy().reshape(-1, 1)\n",
    "y_tr_worthy = train.check_worthiness.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on full training set using best model (Random Forest) and predict probabilities of check-worthiness for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_tr_df, y_tr_worthy)\n",
    "preds_proba = rf.predict_proba(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create correct format for data as specified in README.md and use 'scorer' to compare the system to the gold standard data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['topic_id', 'tweet_id', 'score', 'run_id'])\n",
    "results['tweet_id'] = list(test.index)\n",
    "results['score'] = [x[1] for x in preds_proba]\n",
    "results['topic_id'] = 'covid-19'\n",
    "results['run_id'] = 'TeamGolfModel1'\n",
    "results = results.sort_values(['score'], ascending=False)\n",
    "#results['rank'] = [x for x in range(1, len(test)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237435123072667649</td>\n",
       "      <td>0.715</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1236987957405536256</td>\n",
       "      <td>0.645</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237216806068051968</td>\n",
       "      <td>0.640</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237182053843689474</td>\n",
       "      <td>0.625</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237512557088260097</td>\n",
       "      <td>0.610</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1236911907027791873</td>\n",
       "      <td>0.010</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1236859724353716224</td>\n",
       "      <td>0.005</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237384116141768704</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237179694815969280</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237207721604235264</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TeamGolfModel1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic_id             tweet_id  score          run_id\n",
       "53   covid-19  1237435123072667649  0.715  TeamGolfModel1\n",
       "113  covid-19  1236987957405536256  0.645  TeamGolfModel1\n",
       "77   covid-19  1237216806068051968  0.640  TeamGolfModel1\n",
       "116  covid-19  1237182053843689474  0.625  TeamGolfModel1\n",
       "34   covid-19  1237512557088260097  0.610  TeamGolfModel1\n",
       "..        ...                  ...    ...             ...\n",
       "33   covid-19  1236911907027791873  0.010  TeamGolfModel1\n",
       "66   covid-19  1236859724353716224  0.005  TeamGolfModel1\n",
       "132  covid-19  1237384116141768704  0.000  TeamGolfModel1\n",
       "80   covid-19  1237179694815969280  0.000  TeamGolfModel1\n",
       "2    covid-19  1237207721604235264  0.000  TeamGolfModel1\n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('final_results/system_1_results.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
