{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. English: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('training.tsv', sep='\\t')\n",
    "dev = pd.read_csv('dev.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1234964653014384644</td>\n",
       "      <td>https://twitter.com/EricTrump/status/123496465...</td>\n",
       "      <td>Since this will never get reported by the medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1234869939720216578</td>\n",
       "      <td>https://twitter.com/RealJamesWoods/status/1234...</td>\n",
       "      <td>Thanks, #MichaelBloomberg. Here’s a handy litt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1234873136304267267</td>\n",
       "      <td>https://twitter.com/hayxsmith/status/123487313...</td>\n",
       "      <td>Folks, when you say \"The corona virus isn't a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235071285027147776</td>\n",
       "      <td>https://twitter.com/ipspankajnain/status/12350...</td>\n",
       "      <td>Just 1 case of Corona Virus in India and  peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id             tweet_id  \\\n",
       "0  covid-19  1234964653014384644   \n",
       "1  covid-19  1234869939720216578   \n",
       "2  covid-19  1234873136304267267   \n",
       "3  covid-19  1235071285027147776   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/EricTrump/status/123496465...   \n",
       "1  https://twitter.com/RealJamesWoods/status/1234...   \n",
       "2  https://twitter.com/hayxsmith/status/123487313...   \n",
       "3  https://twitter.com/ipspankajnain/status/12350...   \n",
       "\n",
       "                                          tweet_text  claim  claim_worthiness  \n",
       "0  Since this will never get reported by the medi...      1                 1  \n",
       "1  Thanks, #MichaelBloomberg. Here’s a handy litt...      0                 0  \n",
       "2  Folks, when you say \"The corona virus isn't a ...      0                 0  \n",
       "3  Just 1 case of Corona Virus in India and  peop...      1                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text pre-processing: tokenisation, POS, lemmanisation, stop words, punctuation, emoji, lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zhangyingji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords \n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processor(df):\n",
    "    for i in range(len(df)):\n",
    "        # 1. tokenisation.\n",
    "        token_word = word_tokenize(df.loc[i, 'tweet_text'])\n",
    "        # 2. POS.\n",
    "        token_words = pos_tag(token_word)\n",
    "        # 3. WordNetLemmatizer\n",
    "        words_lematizer = []\n",
    "        wordnet_lematizer = WordNetLemmatizer()\n",
    "        for word, tag in token_words:\n",
    "            if tag.startswith('NN'):\n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='n')  \n",
    "            elif tag.startswith('VB'): \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='v')  \n",
    "            elif tag.startswith('JJ'): \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='a')  \n",
    "            elif tag.startswith('R'): \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='r')\n",
    "            else: \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word)\n",
    "            words_lematizer.append(word_lematizer)\n",
    "        # 4. remove stop words.\n",
    "        cleaned_words = [word for word in words_lematizer if word not in stopwords.words('english')]\n",
    "        # 5. remove punctuation.\n",
    "        characters = [',', '.','DBSCAN', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%','-','...','^','{','}']\n",
    "        words_list = [word for word in cleaned_words if word not in characters]\n",
    "        # 6. lower case.\n",
    "        words_lists = [x.lower() for x in words_list ]\n",
    "        # to string.\n",
    "        text = str()\n",
    "        for w in words_lists:\n",
    "            text+=w\n",
    "            text+=' '\n",
    "        df.loc[i, 'tweet_text'] = remove_emoji(text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = text_processor(train)\n",
    "dev = text_processor(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1234964653014384644</td>\n",
       "      <td>https://twitter.com/EricTrump/status/123496465...</td>\n",
       "      <td>since never get report medium i want share cop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1234869939720216578</td>\n",
       "      <td>https://twitter.com/RealJamesWoods/status/1234...</td>\n",
       "      <td>thanks michaelbloomberg here ’ handy little un...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1234873136304267267</td>\n",
       "      <td>https://twitter.com/hayxsmith/status/123487313...</td>\n",
       "      <td>folks say `` the corona virus n't big deal kil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235071285027147776</td>\n",
       "      <td>https://twitter.com/ipspankajnain/status/12350...</td>\n",
       "      <td>just 1 case corona virus india people crazy ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id             tweet_id  \\\n",
       "0  covid-19  1234964653014384644   \n",
       "1  covid-19  1234869939720216578   \n",
       "2  covid-19  1234873136304267267   \n",
       "3  covid-19  1235071285027147776   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/EricTrump/status/123496465...   \n",
       "1  https://twitter.com/RealJamesWoods/status/1234...   \n",
       "2  https://twitter.com/hayxsmith/status/123487313...   \n",
       "3  https://twitter.com/ipspankajnain/status/12350...   \n",
       "\n",
       "                                          tweet_text  claim  claim_worthiness  \n",
       "0  since never get report medium i want share cop...      1                 1  \n",
       "1  thanks michaelbloomberg here ’ handy little un...      0                 0  \n",
       "2  folks say `` the corona virus n't big deal kil...      0                 0  \n",
       "3  just 1 case corona virus india people crazy ma...      1                 1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235714275752267776</td>\n",
       "      <td>https://twitter.com/julialindau/status/1235714...</td>\n",
       "      <td>i land jfk report coronavirus milan lombardy —...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235256530728972290</td>\n",
       "      <td>https://twitter.com/stayfrea_/status/123525653...</td>\n",
       "      <td>alert️️️ the corona virus spread money if mone...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235648554338791427</td>\n",
       "      <td>https://twitter.com/A6Asap/status/123564855433...</td>\n",
       "      <td>covid-19 health advice️ http //t.co/xssao52smu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235674258858061825</td>\n",
       "      <td>https://twitter.com/DrDenaGrayson/status/12356...</td>\n",
       "      <td>️chinese doctor say autopsy coronavirus victim...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id             tweet_id  \\\n",
       "0  covid-19  1235714275752267776   \n",
       "1  covid-19  1235256530728972290   \n",
       "2  covid-19  1235648554338791427   \n",
       "3  covid-19  1235674258858061825   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/julialindau/status/1235714...   \n",
       "1  https://twitter.com/stayfrea_/status/123525653...   \n",
       "2  https://twitter.com/A6Asap/status/123564855433...   \n",
       "3  https://twitter.com/DrDenaGrayson/status/12356...   \n",
       "\n",
       "                                          tweet_text  claim  claim_worthiness  \n",
       "0  i land jfk report coronavirus milan lombardy —...      1                 1  \n",
       "1  alert️️️ the corona virus spread money if mone...      1                 0  \n",
       "2    covid-19 health advice️ http //t.co/xssao52smu       0                 0  \n",
       "3  ️chinese doctor say autopsy coronavirus victim...      1                 1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.loc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract N-gram based on tf.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "count_vec = CountVectorizer(ngram_range=(1, 3), max_features=100)\n",
    "tf = count_vec.fit_transform(train['tweet_text'].values.astype('U')).toarray()\n",
    "vocab = count_vec.get_feature_names()\n",
    "\n",
    "# td.idf\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3), min_df=1, vocabulary=vocab)\n",
    "tfidf= tfidf_vec.fit_transform(train['tweet_text'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eng_tf = pd.DataFrame(tf, columns=vocab)\n",
    "train_eng_tf.to_csv(\"English_ngram_train_tf.csv\")\n",
    "train_eng_tfidf = pd.DataFrame(tfidf, columns=vocab)\n",
    "train_eng_tfidf.to_csv(\"English_ngram_train_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>19</th>\n",
       "      <th>also</th>\n",
       "      <th>amp</th>\n",
       "      <th>and</th>\n",
       "      <th>breaking</th>\n",
       "      <th>call</th>\n",
       "      <th>care</th>\n",
       "      <th>case</th>\n",
       "      <th>china</th>\n",
       "      <th>...</th>\n",
       "      <th>us</th>\n",
       "      <th>virus</th>\n",
       "      <th>want</th>\n",
       "      <th>we</th>\n",
       "      <th>week</th>\n",
       "      <th>who</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  19  also  amp  and  breaking  call  care  case  china  ...  us  virus  \\\n",
       "0    0   0     0    0    0         0     0     0     0      0  ...   0      0   \n",
       "1    0   0     0    0    0         0     0     0     0      0  ...   0      0   \n",
       "2    0   0     0    0    0         0     0     0     0      0  ...   0      1   \n",
       "\n",
       "   want  we  week  who  work  world  would  year  \n",
       "0     1   0     0    0     0      0      0     0  \n",
       "1     0   0     0    0     0      0      0     0  \n",
       "2     0   0     0    0     0      0      0     0  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eng_tf.loc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1, 3), max_features=100)\n",
    "tf = count_vec.fit_transform(dev['tweet_text'].values.astype('U')).toarray()\n",
    "vocab = count_vec.get_feature_names()\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3), min_df=1, vocabulary=vocab)\n",
    "tfidf= tfidf_vec.fit_transform(dev['tweet_text'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_eng_tf = pd.DataFrame(tf, columns=vocab)\n",
    "dev_eng_tf.to_csv(\"English_ngram_dev_tfidf.csv\")\n",
    "dev_eng_tfidf = pd.DataFrame(tfidf, columns=vocab)\n",
    "dev_eng_tfidf.to_csv(\"English_ngram_dev_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_tfidf_X = np.array(train_eng_tfidf)\n",
    "test_tfidf_X = np.array(dev_eng_tfidf)\n",
    "\n",
    "train_y = np.array(train['claim_worthiness'])\n",
    "test_y = np.array(dev['claim_worthiness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf score:  0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(train_tfidf_X, train_y)\n",
    "print(\"tfidf score: \", clf.score(test_tfidf_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf score:  0.52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_tfidf = SVC(gamma='auto').fit(train_tfidf_X, train_y)\n",
    "print(\"tfidf score: \", clf_tfidf.score(test_tfidf_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf score:  0.49333333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh_tfidf = KNeighborsClassifier(n_neighbors=4).fit(train_tfidf_X, train_y)\n",
    "print(\"tfidf score: \", neigh_tfidf.score(test_tfidf_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. word embedding: mean & min & max using pre-trained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# need to download GoogleNews-vectors-negative300.bin. \n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_X = list()\n",
    "dev_mean_X = list()\n",
    "\n",
    "for i in range(len(train)):\n",
    "    train_text = [model[x] for x in train.loc[i, 'tweet_text'].split(' ') if x in model]\n",
    "    vector = np.array(train_text).mean(axis=0)\n",
    "    train_mean_X.append(vector)\n",
    "    \n",
    "for i in range(len(dev)):\n",
    "    dev_text = [model[x] for x in dev.loc[i, 'tweet_text'].split(' ') if x in model]\n",
    "    vector = np.array(dev_text).mean(axis=0)\n",
    "    dev_mean_X.append(vector) \n",
    "    \n",
    "train_mean_X = np.array(train_mean_X)\n",
    "dev_mean_X = np.array(dev_mean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_X = list()\n",
    "dev_max_X = list()\n",
    "\n",
    "for i in range(len(train)):\n",
    "    train_text = [model[x] for x in train.loc[i, 'tweet_text'].split(' ') if x in model]\n",
    "    vector = np.array(train_text).max(axis=0)\n",
    "    train_max_X.append(vector)\n",
    "    \n",
    "for i in range(len(dev)):\n",
    "    dev_text = [model[x] for x in dev.loc[i, 'tweet_text'].split(' ') if x in model]\n",
    "    vector = np.array(dev_text).max(axis=0)\n",
    "    dev_max_X.append(vector)\n",
    "    \n",
    "train_max_X = np.array(train_max_X)\n",
    "dev_max_X = np.array(dev_max_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min_X = list()\n",
    "dev_min_X = list()\n",
    "\n",
    "for i in range(len(train)):\n",
    "    train_text = [model[x] for x in train.loc[i, 'tweet_text'].split(' ') if x in model]\n",
    "    vector = np.array(train_text).min(axis=0)\n",
    "    train_min_X.append(vector)\n",
    "    \n",
    "for i in range(len(dev)):\n",
    "    dev_text = [model[x] for x in dev.loc[i, 'tweet_text'].split(' ') if x in model]\n",
    "    vector = np.array(dev_text).min(axis=0)\n",
    "    dev_min_X.append(vector)\n",
    "    \n",
    "train_min_X = np.array(train_min_X)\n",
    "dev_min_X = np.array(dev_min_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487, 300)\n",
      "(150, 300)\n"
     ]
    }
   ],
   "source": [
    "print(train_mean_X.shape)\n",
    "print(dev_mean_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. classifier: logistic regression & random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score:  0.7\n",
      "max score:  0.7\n",
      "min score:  0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_mean = LogisticRegression(random_state=0, solver='lbfgs').fit(train_mean_X, train_y)\n",
    "print(\"mean score: \", clf_mean.score(dev_mean_X, test_y))\n",
    "\n",
    "clf_max = LogisticRegression(random_state=0, solver='lbfgs').fit(train_max_X, train_y)\n",
    "print(\"max score: \", clf_max.score(dev_max_X, test_y))\n",
    "\n",
    "clf_min = LogisticRegression(random_state=0, solver='lbfgs').fit(train_min_X, train_y)\n",
    "print(\"min score: \", clf_min.score(dev_min_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(train_mean_X, train_y)\n",
    "preds_proba = rf.predict_proba(dev_mean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235714275752267776</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235256530728972290</td>\n",
       "      <td>0.435</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235648554338791427</td>\n",
       "      <td>0.200</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235674258858061825</td>\n",
       "      <td>0.570</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235663306246860800</td>\n",
       "      <td>0.555</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235436227140055040</td>\n",
       "      <td>0.650</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235602629247537154</td>\n",
       "      <td>0.160</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235566351093137408</td>\n",
       "      <td>0.175</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235620307534258176</td>\n",
       "      <td>0.365</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235758466784014337</td>\n",
       "      <td>0.680</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1235956474955718656</td>\n",
       "      <td>0.665</td>\n",
       "      <td>Model_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_id             tweet_id  score   run_id\n",
       "0   covid-19  1235714275752267776  0.340  Model_1\n",
       "1   covid-19  1235256530728972290  0.435  Model_1\n",
       "2   covid-19  1235648554338791427  0.200  Model_1\n",
       "3   covid-19  1235674258858061825  0.570  Model_1\n",
       "4   covid-19  1235663306246860800  0.555  Model_1\n",
       "5   covid-19  1235436227140055040  0.650  Model_1\n",
       "6   covid-19  1235602629247537154  0.160  Model_1\n",
       "7   covid-19  1235566351093137408  0.175  Model_1\n",
       "8   covid-19  1235620307534258176  0.365  Model_1\n",
       "9   covid-19  1235758466784014337  0.680  Model_1\n",
       "10  covid-19  1235956474955718656  0.665  Model_1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['topic_id', 'tweet_id', 'score', 'run_id'])\n",
    "results['tweet_id'] = list(dev['tweet_id'])\n",
    "results['score'] = [x[1] for x in preds_proba]\n",
    "results['topic_id'] = 'covid-19'\n",
    "results['run_id'] = 'Model_1'\n",
    "\n",
    "results.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('golf_system_results_1.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean:\n",
    "\n",
    "INFO : ======================== RESULTS for golf_system_results_1.tsv ==========================\n",
    "\n",
    "INFO : AVERAGE PRECISION:            0.7929    \n",
    "INFO : ================================================================================\n",
    "\n",
    "INFO : RECIPROCAL RANK:              1.0000    \n",
    "INFO : ================================================================================\n",
    "\n",
    "INFO : R-PRECISION (R=72):           0.7083    \n",
    "INFO : ================================================================================\n",
    "\n",
    "INFO : PRECISION@N:                  @1        @3        @5        @10       @20       @50       \n",
    "INFO :                               1.0000    1.0000    1.0000    1.0000    0.9500    0.7600    \n",
    "INFO : ================================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
