{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final System 2 - fastText w/ TFIDF on V2 Data\n",
    "\n",
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822 training instances\n",
      "140 test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/tommcdonald/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tommcdonald/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/tommcdonald/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import emoji\n",
    "import fasttext\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "train = pd.read_csv('final_data/training_v2.tsv', sep='\\t')\n",
    "dev = pd.read_csv('final_data/dev_v2.tsv', sep='\\t')\n",
    "train = train.append(dev, ignore_index=True)\n",
    "test = pd.read_csv('final_data/test-input.tsv', sep='\\t')\n",
    "\n",
    "print(len(train), 'training instances')\n",
    "print(len(test), 'test instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "url_pattern = r\"https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}\"\n",
    "\n",
    "def text_processor(df):\n",
    "    for i in range(len(df)):\n",
    "        # 1. remove url.\n",
    "        text = re.sub(url_pattern, \"\", df.loc[i, 'tweet_text'])\n",
    "        # 2. tokenisation.\n",
    "        token_word = word_tokenize(text)\n",
    "        # 3. POS.\n",
    "        token_words = pos_tag(token_word)\n",
    "        # 4. WordNetLemmatizer\n",
    "        words_lematizer = []\n",
    "        wordnet_lematizer = WordNetLemmatizer()\n",
    "        for word, tag in token_words:\n",
    "            if tag.startswith('NN'):\n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='n')  \n",
    "            elif tag.startswith('VB'): \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='v')  \n",
    "            elif tag.startswith('JJ'): \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='a')  \n",
    "            elif tag.startswith('R'): \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word, pos='r')\n",
    "            else: \n",
    "                word_lematizer =  wordnet_lematizer.lemmatize(word)\n",
    "            words_lematizer.append(word_lematizer)\n",
    "        # 5. lower case and remove stop words.\n",
    "        cleaned_words = [word.lower() for word in words_lematizer if word.lower() not in stopwords.words('english')]\n",
    "        # 6. remove punctuation.\n",
    "        characters = [',','â€™', '\\'','.','DBSCAN', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%','-','...','^','{','}']\n",
    "        words_lists = [word for word in cleaned_words if word not in characters]\n",
    "        text = str()\n",
    "        for w in words_lists:\n",
    "            text+=w\n",
    "            text+=' '\n",
    "        # 7. remove emoji\n",
    "        df.loc[i, 'tweet_text'] = remove_emoji(text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fast = text_processor(train).drop(['claim', 'topic_id', 'tweet_id', 'tweet_url'], axis=1)\n",
    "test_fast = text_processor(test).drop(['topic_id', 'tweet_id', 'tweet_url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>check_worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>since never get report medium want share copy ...</td>\n",
       "      <td>__label__Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks michaelbloomberg handy little unintenti...</td>\n",
       "      <td>__label__No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folks say `` corona virus n't big deal kill di...</td>\n",
       "      <td>__label__No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 case corona virus india people crazy mask da...</td>\n",
       "      <td>__label__No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text check_worthiness\n",
       "0  since never get report medium want share copy ...     __label__Yes\n",
       "1  thanks michaelbloomberg handy little unintenti...      __label__No\n",
       "2  folks say `` corona virus n't big deal kill di...      __label__No\n",
       "3  1 case corona virus india people crazy mask da...      __label__No"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fast['check_worthiness'] = np.where(train_fast['check_worthiness'] == 1, '__label__Yes', '__label__No') \n",
    "\n",
    "train_fast.loc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fast[['check_worthiness', 'tweet_text']].to_csv('final_data/train_fast.txt', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fast[['tweet_text']].to_csv('final_data/test_fast.txt', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: 10 epochs, 0.300000 lr, 4 - grams, ws = 5, softmax loss\n",
      "Average Precision of 0.813\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters: %d epochs, %f lr, %d - grams, ws = %d, %s loss' % \\\n",
    "      (best_e, best_lr, best_n, best_ws, best_loss))\n",
    "print('Average Precision of %.3f' % best_p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1236947198971125761</td>\n",
       "      <td>0.619843</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237382759812861952</td>\n",
       "      <td>0.614859</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237576863901290496</td>\n",
       "      <td>0.592716</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237148966204125186</td>\n",
       "      <td>0.567603</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237512557088260097</td>\n",
       "      <td>0.562691</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237226775148662784</td>\n",
       "      <td>0.268967</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237005180199219203</td>\n",
       "      <td>0.234906</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1237179694815969280</td>\n",
       "      <td>0.198092</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1236859724353716224</td>\n",
       "      <td>0.126218</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1236911907027791873</td>\n",
       "      <td>0.113770</td>\n",
       "      <td>TeamGolfModel2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic_id             tweet_id     score          run_id\n",
       "24   covid-19  1236947198971125761  0.619843  TeamGolfModel2\n",
       "110  covid-19  1237382759812861952  0.614859  TeamGolfModel2\n",
       "76   covid-19  1237576863901290496  0.592716  TeamGolfModel2\n",
       "65   covid-19  1237148966204125186  0.567603  TeamGolfModel2\n",
       "34   covid-19  1237512557088260097  0.562691  TeamGolfModel2\n",
       "..        ...                  ...       ...             ...\n",
       "35   covid-19  1237226775148662784  0.268967  TeamGolfModel2\n",
       "133  covid-19  1237005180199219203  0.234906  TeamGolfModel2\n",
       "80   covid-19  1237179694815969280  0.198092  TeamGolfModel2\n",
       "66   covid-19  1236859724353716224  0.126218  TeamGolfModel2\n",
       "33   covid-19  1236911907027791873  0.113770  TeamGolfModel2\n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fasttext.train_supervised(input=\"data/train_fast.txt\",\n",
    "                                  epoch=10, lr=0.3, wordNgrams=4,\n",
    "                                  ws=5, loss='softmax')\n",
    "preds_proba = []\n",
    "\n",
    "for tweet in test_fast['tweet_text']:\n",
    "    pred = model.predict(tweet)\n",
    "    if pred[0][0] == '__label__Yes':\n",
    "        preds_proba.append(pred[1][0])\n",
    "    else:\n",
    "        preds_proba.append(1 - pred[1][0])\n",
    "\n",
    "results = pd.DataFrame(columns=['topic_id',  'tweet_id', 'score', 'run_id'])\n",
    "results['tweet_id'] = test['tweet_id']\n",
    "results['score'] = preds_proba\n",
    "results['topic_id'] = 'covid-19'\n",
    "results['run_id'] = 'TeamGolfModel2'\n",
    "results = results.sort_values(['score'], ascending=False)\n",
    "#results['rank'] = [x for x in range(1, len(test)+1)]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('final_results/system_2_results.tsv', sep='\\t', header=False, index=False, float_format='%.15f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
