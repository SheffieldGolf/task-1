{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.readers.CT20_AR_reader import readTweets, readLabels, readTopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tweets, labels & topics using helper functions\n",
    "tweets = readTweets()\n",
    "labels = readLabels()\n",
    "topics = readTopics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "tweets_df = labels\n",
    "tweets_df['full_text_ar'] = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    # For each tweet ID, find row with that ID in DataFrame and add Arabic text to that row\n",
    "    tweet_idx = tweets_df[tweets_df['tweetID'] == tweet['id']].index[0]\n",
    "    tweets_df.iloc[tweet_idx, tweets_df.columns.get_loc('full_text_ar')] = tweet['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topicID</th>\n",
       "      <th>tweetID</th>\n",
       "      <th>label</th>\n",
       "      <th>full_text_ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221585936095555584</td>\n",
       "      <td>0</td>\n",
       "      <td>بين ثورة لبنان ال١٠٠ يوم وبين ٤٠ العراق \\nتتر ورُعاع ايران ما زالت رائحة البارود والنار تفوح منهم ، من حرق الخيم وإطلاق الرصاص على المتظاهرين \\nوأكتافهم تعبت من بناء حواجز بينهم وبين المواطنين لحماية مملكتهم الهشة \\n\\nرُعاع القرن الحالي \\n#ايران #العراق #لبنان \\n#لبنان_النا_مش_الكن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221587916750753793</td>\n",
       "      <td>0</td>\n",
       "      <td>#لبنان_النا_مش_الكن\\nأرملة فقيرة\\nعليهاإيقاف خدمات\\nخلونانفرحهاوعيالها\\nليس لهم بعد الله سبحانه إلاأنتم\\nبيت أجاروعايشه ع الضمان\\nوفاتورة الكهرباء أهم وأقل شي سداد نص الفاتورة\\nوالفصل بعديوم\\nأسأل الله يفرج همهم\\nوالله مبلغهم مو معجزة\\nالتنفيذ؛2030633080(77ألف)\\nالكهرباء؛10097517557(7آلاف) https://t.co/1kzQxf2XeB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221602993918894081</td>\n",
       "      <td>0</td>\n",
       "      <td>#جدار_العار\\nالحيتان الحيطان..عمروا بينن و بين الشعب..حيطان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221653116036304896</td>\n",
       "      <td>0</td>\n",
       "      <td>هل يحمي #جدار_العار السلطة السياسية الفاسدة من شعبها الثائر ضدها؟ https://t.co/HYQnmpI07L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221663019345874944</td>\n",
       "      <td>1</td>\n",
       "      <td>موازنة شو؟!\\n١- ارقام غير صحيحة.\\n٢- حكومة لم تنل الثقة بعد، يعني غير مسؤولة عن ارقام وضعتها الحكومة السابقة.\\nانّو جلسة استفزاز للشعب؟!\\nاذا بدكن الناس تعطيكم فرصة، بالقليلة كونوا منطقيين!\\n#لبنان_ينتفض</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221688210834759680</td>\n",
       "      <td>0</td>\n",
       "      <td>#سندريلات_مرهج :تزامناً مع انعقاد جلسة #الموازنة النيابية اليوم الاثنين، تابعونا (إن شئتم) عبر شاشة NBN الساعة  ١٠ ونصف صباحا في حديث سياسي مباشر حول المستجدات السياسية على الساحتين المحلية والدولية بضيافة الإعلامية أمل فضول 🙋‍♀️\\n@nbntweets https://t.co/Tk5frOg2gh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topicID              tweetID  label  \\\n",
       "0  CT20-AR-05  1221585936095555584  0       \n",
       "1  CT20-AR-05  1221587916750753793  0       \n",
       "2  CT20-AR-05  1221602993918894081  0       \n",
       "3  CT20-AR-05  1221653116036304896  0       \n",
       "4  CT20-AR-05  1221663019345874944  1       \n",
       "5  CT20-AR-05  1221688210834759680  0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                 full_text_ar  \n",
       "0  بين ثورة لبنان ال١٠٠ يوم وبين ٤٠ العراق \\nتتر ورُعاع ايران ما زالت رائحة البارود والنار تفوح منهم ، من حرق الخيم وإطلاق الرصاص على المتظاهرين \\nوأكتافهم تعبت من بناء حواجز بينهم وبين المواطنين لحماية مملكتهم الهشة \\n\\nرُعاع القرن الحالي \\n#ايران #العراق #لبنان \\n#لبنان_النا_مش_الكن                                  \n",
       "1  #لبنان_النا_مش_الكن\\nأرملة فقيرة\\nعليهاإيقاف خدمات\\nخلونانفرحهاوعيالها\\nليس لهم بعد الله سبحانه إلاأنتم\\nبيت أجاروعايشه ع الضمان\\nوفاتورة الكهرباء أهم وأقل شي سداد نص الفاتورة\\nوالفصل بعديوم\\nأسأل الله يفرج همهم\\nوالله مبلغهم مو معجزة\\nالتنفيذ؛2030633080(77ألف)\\nالكهرباء؛10097517557(7آلاف) https://t.co/1kzQxf2XeB  \n",
       "2  #جدار_العار\\nالحيتان الحيطان..عمروا بينن و بين الشعب..حيطان                                                                                                                                                                                                                                                                 \n",
       "3  هل يحمي #جدار_العار السلطة السياسية الفاسدة من شعبها الثائر ضدها؟ https://t.co/HYQnmpI07L                                                                                                                                                                                                                                   \n",
       "4  موازنة شو؟!\\n١- ارقام غير صحيحة.\\n٢- حكومة لم تنل الثقة بعد، يعني غير مسؤولة عن ارقام وضعتها الحكومة السابقة.\\nانّو جلسة استفزاز للشعب؟!\\nاذا بدكن الناس تعطيكم فرصة، بالقليلة كونوا منطقيين!\\n#لبنان_ينتفض                                                                                                                 \n",
       "5  #سندريلات_مرهج :تزامناً مع انعقاد جلسة #الموازنة النيابية اليوم الاثنين، تابعونا (إن شئتم) عبر شاشة NBN الساعة  ١٠ ونصف صباحا في حديث سياسي مباشر حول المستجدات السياسية على الساحتين المحلية والدولية بضيافة الإعلامية أمل فضول 🙋‍♀️\\n@nbntweets https://t.co/Tk5frOg2gh                                                   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.loc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Arabic text pre-processing: (using Farasa api)\n",
    "\n",
    ">1. remove url.\n",
    "2. diacritization.\n",
    "3. tokenisation.\n",
    "4. lemmanisation.\n",
    "5. remove stop words.\n",
    "6. remove punctuation.\n",
    "7. remove emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "url_pattern = r\"https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Farasa API.\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenizer(text):\n",
    "    import http.client # import http.client in function to avoid connected time out.\n",
    "    import json\n",
    "    text = text.replace('\\n', ' ').replace('\"', '') # otherwise JSONDecodeError.\n",
    "    conn = http.client.HTTPSConnection(\"farasa-api.qcri.org\")\n",
    "    payload = \"{\\\"text\\\":\\\"%s\\\"}\"% text\n",
    "    payload = payload.encode('utf-8')\n",
    "    headers = { 'content-type': \"application/json\", 'cache-control': \"no-cache\", }\n",
    "    conn.request(\"POST\", \"/msa/webapi/segmenter\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode('utf-8')\n",
    "    data_dict = json.loads(data)\n",
    "    return data_dict['segtext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    import http.client\n",
    "    import json\n",
    "    text = text.replace('\\n', ' ').replace('\"', '') \n",
    "    conn = http.client.HTTPSConnection(\"farasa-api.qcri.org\")\n",
    "    payload = \"{\\\"text\\\":\\\"%s\\\"}\"% text\n",
    "    payload = payload.encode('utf-8')\n",
    "    headers = { 'content-type': \"application/json\", 'cache-control': \"no-cache\", }\n",
    "    conn.request(\"POST\", \"/msa/webapi/lemma\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode('utf-8')\n",
    "    data_dict = json.loads(data)\n",
    "    return data_dict['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diacritizer(text):\n",
    "    import http.client\n",
    "    import json\n",
    "    text = text.replace('\\n', ' ').replace('\"', '') \n",
    "    conn = http.client.HTTPSConnection(\"farasa-api.qcri.org\")\n",
    "    payload = \"{\\\"text\\\":\\\"%s\\\"}\"% text\n",
    "    payload = payload.encode('utf-8')\n",
    "    headers = { 'content-type': \"application/json\", 'cache-control': \"no-cache\", }\n",
    "    conn.request(\"POST\", \"/msa/webapi/diacritizeV2\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode('utf-8')\n",
    "    data_dict = json.loads(data)\n",
    "    return data_dict['output'] # return string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(l): # Farasa api accept string as input.\n",
    "    text = str()\n",
    "    for w in l:\n",
    "        text+= w\n",
    "        text+=' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processor(df):\n",
    "    for i in range(len(df)):\n",
    "        # 1. remove url.\n",
    "        text = re.sub(url_pattern, \"\", df.loc[i, 'full_text_ar'])\n",
    "        # 2. diacritization.\n",
    "        diac_text = diacritizer(text)\n",
    "        # 3. tokenisation.\n",
    "        token_word = tokenizer(diac_text)\n",
    "        text = list_to_str(token_word)\n",
    "        # 4. Lemmatizer.\n",
    "        token_word = lemmatizer(text)\n",
    "        # 5. remove stop words.\n",
    "        cleaned_words = [word for word in token_word if word not in stopwords.words(\"arabic\")]\n",
    "        # 6. remove punctuation.\n",
    "        characters = [',','’', '\\'','.','DBSCAN', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%','-','...','^','{','}']\n",
    "        words_lists = [word for word in cleaned_words if word not in characters]\n",
    "        text = list_to_str(words_lists)\n",
    "        # 7. remove emoji\n",
    "        df.loc[i, 'full_text_ar'] = remove_emoji(text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text_processor(tweets_df) # 20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_Arabic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topicID</th>\n",
       "      <th>tweetID</th>\n",
       "      <th>label</th>\n",
       "      <th>full_text_ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221585936095555584</td>\n",
       "      <td>0</td>\n",
       "      <td>ثور ة لبنان ال يوم و ال عراق تتر و رعاع ايران زال ت رائح ة ال بارود و ال نار فاح ، حرق ال خيم و إطلاق ال رصاص ال متظاهر ين و كتف تعب ت بناء حاجز و ال مواطن ين ل حماي ة مملك ت ال هش ة رعاع ال قرن ال حال #ايران #العراق #لبنان #لبنان_النا_مش_الكن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221587916750753793</td>\n",
       "      <td>0</td>\n",
       "      <td>#لبنان_النا_مش_الكن أرمل ة فقير ة عليهاإيقاف خدم ات خلونانفرحهاوعيالها ل الله سبحان ه إلاأنتم بيت أجاروعايشه ع ال ضمان و فاتور ة ال كهرباء أهم و شي سداد نص ال فاتور ة و ال فصل بعديوم سأل الله أفرج و الله مبلغ مو معجز ة ال تنفيذ ؛ 2030633080 77 ألف ال كهرباء ؛ 10097517557 7 ألف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221602993918894081</td>\n",
       "      <td>0</td>\n",
       "      <td>#جدار_العار ال حو ت ال حيطان عمر وا ن و ال شعب حيطان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT20-AR-05</td>\n",
       "      <td>1221653116036304896</td>\n",
       "      <td>0</td>\n",
       "      <td>حمى #جدار_العار ال سلط ة ال سياسي ة ال فاسد ة شعب ال ثائر ضد ؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topicID              tweetID  label  \\\n",
       "0  CT20-AR-05  1221585936095555584  0       \n",
       "1  CT20-AR-05  1221587916750753793  0       \n",
       "2  CT20-AR-05  1221602993918894081  0       \n",
       "3  CT20-AR-05  1221653116036304896  0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                             full_text_ar  \n",
       "0  ثور ة لبنان ال يوم و ال عراق تتر و رعاع ايران زال ت رائح ة ال بارود و ال نار فاح ، حرق ال خيم و إطلاق ال رصاص ال متظاهر ين و كتف تعب ت بناء حاجز و ال مواطن ين ل حماي ة مملك ت ال هش ة رعاع ال قرن ال حال #ايران #العراق #لبنان #لبنان_النا_مش_الكن                                     \n",
       "1  #لبنان_النا_مش_الكن أرمل ة فقير ة عليهاإيقاف خدم ات خلونانفرحهاوعيالها ل الله سبحان ه إلاأنتم بيت أجاروعايشه ع ال ضمان و فاتور ة ال كهرباء أهم و شي سداد نص ال فاتور ة و ال فصل بعديوم سأل الله أفرج و الله مبلغ مو معجز ة ال تنفيذ ؛ 2030633080 77 ألف ال كهرباء ؛ 10097517557 7 ألف   \n",
       "2  #جدار_العار ال حو ت ال حيطان عمر وا ن و ال شعب حيطان                                                                                                                                                                                                                                    \n",
       "3  حمى #جدار_العار ال سلط ة ال سياسي ة ال فاسد ة شعب ال ثائر ضد ؟                                                                                                                                                                                                                          "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aravec:\n",
    "\n",
    "download pre-trained word embedding: https://github.com/bakrianoo/aravec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "\n",
    "from utilities import * # import utilities.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = gensim.models.Word2Vec.load('tweet_cbow_300/tweets_cbow_300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = t_model.wv['ال']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_mean_X = list()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    train_text = [t_model.wv[x] for x in df.loc[i, 'full_text_ar'].split(' ') if x in t_model]\n",
    "    vector = np.array(train_text).mean(axis=0)\n",
    "    train_mean_X.append(vector)\n",
    "     \n",
    "train_mean_X = np.array(train_mean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 4)\n",
      "(1500, 300)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "print(train_mean_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_y = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "train_mean_X, dev_mean_X, train_y, test_y = train_test_split(train_mean_X, train_y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 300)\n",
      "(450, 300)\n",
      "(1050,)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "print(train_mean_X.shape)\n",
    "print(dev_mean_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score:  0.7666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_mean = LogisticRegression(random_state=0, solver='lbfgs').fit(train_mean_X, train_y)\n",
    "print(\"mean score: \", clf_mean.score(dev_mean_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
